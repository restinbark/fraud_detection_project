# ğŸ•µï¸â€â™€ï¸ Fraud Detection Project

This project focuses on building and interpreting machine learning models to detect fraudulent transactions using anonymized user data. The goal is to improve fraud detection accuracy and provide transparency through model interpretability tools like SHAP.

---

## ğŸ“ Project Structure

```bash
fraud_detection_project/
â”‚
â”œâ”€â”€ data/                         # Raw data
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for each task
â”‚   â”œâ”€â”€ 01_data_analysis_preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_model_building_training.ipynb
â”‚   â””â”€â”€ 03_shap.ipynb
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ data/                    # Cleaned & split data
â”‚   â””â”€â”€ figures/                 # Visualizations and plots
â”‚
â”œâ”€â”€ models/                      # Saved model files
â”œâ”€â”€ README.md                    # Project summary
â””â”€â”€ requirements.txt             # Python dependencies

ğŸ“Œ Task Overview
ğŸ§¹ Task 1: Data Cleaning & Preprocessing
Handled missing values and duplicates

Merged IP address data with transaction data

Encoded categorical features

Addressed class imbalance using SMOTE

ğŸ¤– Task 2: Model Building & Evaluation
Trained Logistic Regression, Random Forest, and XGBoost classifiers

Evaluated models on metrics: Accuracy, Precision, Recall, F1-score, ROC-AUC

Random Forest and XGBoost showed superior performance

ğŸ“Š Task 3: Model Interpretability
Used SHAP to explain feature contributions in XGBoost

Generated beeswarm, bar, and waterfall plots for global and local interpretations

ğŸ“ˆ Visual Results
ğŸ”¹ Univariate & Bivariate Plots
![Age Distribution](https://raw.githubusercontent.com/restinbark/fraud_detection_project/master/outputs/figures/univariate_age.png)

![Class Distribution](https://raw.githubusercontent.com/restinbark/fraud_detection_project/master/outputs/figures/univariate_class_distribution.png)

![Purchase vs Age](https://raw.githubusercontent.com/restinbark/fraud_detection_project/master/outputs/figures/bivariate_purchase_value_by_class.png)



ğŸ” Model Evaluation Summary
Model	Accuracy	Precision	Recall	F1-score	ROC AUC
LogisticRegression	73%	19%	59%	29%	0.70
Random Forest	95%	82%	53%	65%	0.775
XGBoost	95%	91%	53%	67%	0.765

âœ… Recommended Model: XGBoost
Provides strong performance and better interpretability with SHAP

ğŸ” SHAP Interpretability Plots



âœ… Conclusion
This project demonstrates an end-to-end ML pipeline for fraud detection:

Preprocessing, EDA, and SMOTE for class balance

Multiple model training and evaluation

Interpretation using SHAP to build trust in decisions

ğŸš€ Future work: Streamlit dashboard and real-time fraud monitoring

ğŸ“¦ Requirements
bash
pip install -r requirements.

ğŸ™Œ Author
Barkilign Mulatu | 
